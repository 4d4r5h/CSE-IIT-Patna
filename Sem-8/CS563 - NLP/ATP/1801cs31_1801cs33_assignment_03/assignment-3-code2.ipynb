{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Natural Language Processing\n",
        "## Assignment 3 - Machine Translation\n",
        "### Code 2 - With Attention\n",
        "### Students\n",
        "- M Maheeth Reddy (1801CS31)\n",
        "- Nischal A (1801CS33)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Hdp1S1cWhn7"
      },
      "outputs": [],
      "source": [
        "from io import open\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "\n",
        "import string\n",
        "from string import digits\n",
        "\n",
        "from pickle import dump, load\n",
        "\n",
        "import unicodedata\n",
        "from unicodedata import normalize\n",
        "\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from numpy import array, argmax\n",
        "from numpy.random import rand, shuffle\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu\n",
        "\n",
        "\n",
        "import sklearn\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "import scipy\n",
        "import statsmodels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aApRwSzKWmtV"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e9H0SX-WpBe",
        "outputId": "1da4d81d-812c-4523-b069-b672fd09e646"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-04-07 11:41:09--  https://docs.google.com/uc?export=download&confirm=&id=1iljWhk1LVNEdXOYyfxCZd_Osv9D5TJ76\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.195.113, 74.125.195.101, 74.125.195.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.195.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0o-bs-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/grtkss6ei1b9t30bh5ht3ql56mbs17c2/1649331600000/15072518060054569691/*/1iljWhk1LVNEdXOYyfxCZd_Osv9D5TJ76?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-04-07 11:41:10--  https://doc-0o-bs-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/grtkss6ei1b9t30bh5ht3ql56mbs17c2/1649331600000/15072518060054569691/*/1iljWhk1LVNEdXOYyfxCZd_Osv9D5TJ76?e=download\n",
            "Resolving doc-0o-bs-docs.googleusercontent.com (doc-0o-bs-docs.googleusercontent.com)... 74.125.197.132, 2607:f8b0:400e:c03::84\n",
            "Connecting to doc-0o-bs-docs.googleusercontent.com (doc-0o-bs-docs.googleusercontent.com)|74.125.197.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 889658 (869K) [application/x-zip-compressed]\n",
            "Saving to: ‘assign4dataset.zip’\n",
            "\n",
            "assign4dataset.zip  100%[===================>] 868.81K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2022-04-07 11:41:10 (147 MB/s) - ‘assign4dataset.zip’ saved [889658/889658]\n",
            "\n",
            "Archive:  assign4dataset.zip\n",
            "  inflating: english.train.txt       \n",
            "  inflating: hindi.test.txt          \n",
            "  inflating: hindi.train.txt         \n",
            "  inflating: english.test.txt        \n"
          ]
        }
      ],
      "source": [
        "# !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1iljWhk1LVNEdXOYyfxCZd_Osv9D5TJ76' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1iljWhk1LVNEdXOYyfxCZd_Osv9D5TJ76\" -O assign4dataset.zip && rm -rf /tmp/cookies.txt\n",
        "# ! unzip assign4dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kfq3METaWsbI"
      },
      "outputs": [],
      "source": [
        "token_SOS = 0\n",
        "token_EOS = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word_to_index = {\"sos\": 0, \"eos\": 1}\n",
        "        self.word_to_count = {}\n",
        "        self.index_to_word = {0: \"sos\", 1: \"eos\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word_to_index:\n",
        "            self.word_to_index[word] = self.n_words\n",
        "            self.word_to_count[word] = 1\n",
        "            self.index_to_word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word_to_count[word] += 1\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxN7Kq2DdmS7"
      },
      "outputs": [],
      "source": [
        "def eng_sent_preprocessor(sent):\n",
        "    sent = sent.lower()\n",
        "    sent = clean_txt(sent)\n",
        "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "    sent = normalize('NFD', sent).encode('ascii', 'ignore')\n",
        "    sent = sent.decode('UTF-8')\n",
        "    sent = sent.split()\n",
        "    sent = [re_print.sub('', w) for w in sent]\n",
        "    sent = [word for word in sent if word.isalpha()]\n",
        "    sent = ' '.join(sent)\n",
        "    return sent\n",
        "\n",
        "\n",
        "def hin_sent_preprocessor(sent):\n",
        "    sent = re.sub('[a-zA-Z]', '', sent)\n",
        "    sent = clean_txt(sent)\n",
        "    exclude = set(string.punctuation)\n",
        "    remove_digits = str.maketrans('', '', string.digits)\n",
        "    sent = re.sub(\"'\", '', sent)\n",
        "    sent = ''.join(ch for ch in sent if ch not in exclude)\n",
        "    sent = sent.translate(remove_digits)\n",
        "    sent = re.sub(\"[२३०८१५७९४६]\", \"\", sent)\n",
        "    sent = sent.strip()\n",
        "    sent = re.sub(\" +\", \" \", sent)\n",
        "    return (sent)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1yqsiMCdj9G"
      },
      "outputs": [],
      "source": [
        "def doc_reader(filename):\n",
        "    with open(filename, mode='rt', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "\n",
        "def make_pairs(eng_txt, hin_txt):\n",
        "    eng_lines = eng_txt.strip().split('\\n')\n",
        "    hin_lines = hin_txt.strip().split('\\n')\n",
        "\n",
        "    pairs = []\n",
        "    for i in range(len(hin_lines)):\n",
        "        pairs.append([])\n",
        "        pairs[i].append(eng_sent_preprocessor(eng_lines[i]))\n",
        "        pairs[i].append(hin_sent_preprocessor(hin_lines[i]))\n",
        "    return pairs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-JwzF6-dkib"
      },
      "outputs": [],
      "source": [
        "def clean_txt(txt):\n",
        "    txt = txt.replace(u',', '').replace(u'\"', '').replace(u'\"', '').replace(u\"‘‘\", '').replace(u\"’’\", '').replace(u\"''\", '').replace(u\"।\", '').replace(u',', '').replace(u'\"', '').replace(u'(', '').replace(u')', '').replace(u'\"', '').replace(\n",
        "        u':', '').replace(u\"'\", '').replace(u\"‘‘\", '').replace(u\"’’\", '').replace(u\"''\", '').replace(u\".\", '').replace(u\"-\", '').replace(u\"।\", '').replace(u\"?\", '').replace(u\"\\\\\", '').replace(u\"_\", '').replace(\"'\", \"\").replace('\"', \"\")\n",
        "    txt = re.sub(\"'\", '', txt)\n",
        "    txt = re.sub(\"’\", '', txt)\n",
        "    txt = re.sub('[0-9+\\-*/.%]', '', txt)\n",
        "    txt = txt.strip()\n",
        "    txt = re.sub(' +', ' ', txt)\n",
        "    txt = ''.join(ch for ch in txt if ch not in set(string.punctuation))\n",
        "    return txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZPl9mbydqjm"
      },
      "outputs": [],
      "source": [
        "def data_prepare(pairs):\n",
        "    lang_eng = Lang('eng')\n",
        "    lang_hin = Lang('hin')\n",
        "    \n",
        "    for pair in pairs:\n",
        "        lang_eng.addSentence(pair[0])\n",
        "        lang_hin.addSentence(pair[1])\n",
        "    return lang_eng, lang_hin\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSzx9lrrdtgv"
      },
      "outputs": [],
      "source": [
        "eng_train_txt = doc_reader('english.train.txt')\n",
        "hin_train_txt = doc_reader('hindi.train.txt')\n",
        "train_pair = make_pairs(eng_train_txt, hin_train_txt)\n",
        "lang_eng, lang_hin = data_prepare(train_pair)\n",
        "\n",
        "train_df = pd.DataFrame(train_pair)\n",
        "train_df.columns = [\"english\", \"hindi\"]\n",
        "\n",
        "list_len = []\n",
        "for l in train_df.english:\n",
        "    list_len.append(len(l.split(' ')))\n",
        "eng_max_len = np.max(list_len)\n",
        "\n",
        "list_len = []\n",
        "for l in train_df.hindi:\n",
        "    list_len.append(len(l.split(' ')))\n",
        "hin_max_len = np.max(list_len)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jOxbCUKUdvjo",
        "outputId": "cc13b7ef-58ee-4eb9-8922-77386619b90d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c1310377-619c-4514-a402-d982a6cfb9ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>hindi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>give your application an accessibility workout</td>\n",
              "      <td>अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>accerciser accessibility explorer</td>\n",
              "      <td>एक्सेर्साइसर पहुंचनीयता अन्वेषक</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the default plugin layout for the bottom panel</td>\n",
              "      <td>निचले पटल के लिए डिफोल्ट प्लगइन खाका</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the default plugin layout for the top panel</td>\n",
              "      <td>ऊपरी पटल के लिए डिफोल्ट प्लगइन खाका</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a list of plugins that are disabled by default</td>\n",
              "      <td>उन प्लगइनों की सूची जिन्हें डिफोल्ट रूप से निष...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>audio test</td>\n",
              "      <td>ऑडियो जाँच</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>silent</td>\n",
              "      <td>मूक</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>video test</td>\n",
              "      <td>वीडियो जाँच</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>crazy</td>\n",
              "      <td>दीवाना</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>screencast</td>\n",
              "      <td>स्क्रीनकास्ट</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1310377-619c-4514-a402-d982a6cfb9ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c1310377-619c-4514-a402-d982a6cfb9ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c1310377-619c-4514-a402-d982a6cfb9ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                              english  \\\n",
              "0      give your application an accessibility workout   \n",
              "1                   accerciser accessibility explorer   \n",
              "2      the default plugin layout for the bottom panel   \n",
              "3         the default plugin layout for the top panel   \n",
              "4      a list of plugins that are disabled by default   \n",
              "...                                               ...   \n",
              "49995                                      audio test   \n",
              "49996                                          silent   \n",
              "49997                                      video test   \n",
              "49998                                           crazy   \n",
              "49999                                      screencast   \n",
              "\n",
              "                                                   hindi  \n",
              "0        अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें  \n",
              "1                        एक्सेर्साइसर पहुंचनीयता अन्वेषक  \n",
              "2                   निचले पटल के लिए डिफोल्ट प्लगइन खाका  \n",
              "3                    ऊपरी पटल के लिए डिफोल्ट प्लगइन खाका  \n",
              "4      उन प्लगइनों की सूची जिन्हें डिफोल्ट रूप से निष...  \n",
              "...                                                  ...  \n",
              "49995                                         ऑडियो जाँच  \n",
              "49996                                                मूक  \n",
              "49997                                        वीडियो जाँच  \n",
              "49998                                             दीवाना  \n",
              "49999                                       स्क्रीनकास्ट  \n",
              "\n",
              "[50000 rows x 2 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHRKCLf6eJhN"
      },
      "outputs": [],
      "source": [
        "test_eng_text = doc_reader('english.test.txt')\n",
        "test_hindi_text = doc_reader('hindi.test.txt')\n",
        "test_pair = make_pairs(test_eng_text, test_hindi_text)\n",
        "\n",
        "for pair in test_pair:\n",
        "    lang_eng.addSentence(pair[0])\n",
        "    lang_hin.addSentence(pair[1])\n",
        "\n",
        "test_df = pd.DataFrame(test_pair)\n",
        "test_df.columns = [\"english\", \"hindi\"]\n",
        "\n",
        "list_len = []\n",
        "for l in test_df.english:\n",
        "    list_len.append(len(l.split(' ')))\n",
        "eng_max_len = np.max(list_len)\n",
        "\n",
        "list_len = []\n",
        "for l in test_df.hindi:\n",
        "    list_len.append(len(l.split(' ')))\n",
        "hin_max_len = np.max(list_len)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_fgWliWGdykJ",
        "outputId": "24c991dc-d004-4809-c87d-d35083382cb1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ed2fb9b7-a2c5-4e9e-9fba-458fb7cf2a14\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>hindi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a black box in your car</td>\n",
              "      <td>आपकी कार में ब्लैक बॉक्स</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>as americas road planners struggle to find the...</td>\n",
              "      <td>जबकि अमेरिका के सड़क योजनाकार ध्वस्त होते हुए ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the devices which track every mile a motorist ...</td>\n",
              "      <td>यह डिवाइस जो मोटरचालक द्वारा वाहन चलाए गए प्रत...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the usually dull arena of highway planning has...</td>\n",
              "      <td>आम तौर पर हाईवे नियोजन जैसा उबाऊ काम भी अचानक ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>libertarians have joined environmental groups ...</td>\n",
              "      <td>आपने द्वारा ड्राइव किए गए मील तथा संभवतः ड्राइ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2502</th>\n",
              "      <td>it is noteworthy that both nita and isha are p...</td>\n",
              "      <td>गौरतलब है कि नीता और ईशा दोनों ही प्रोफेशनल क्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2503</th>\n",
              "      <td>vips have been invited to this royal party</td>\n",
              "      <td>इस शाही पार्टी के लिए वीवीआईपी लोगों को भी आमं...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2504</th>\n",
              "      <td>these include the jodhpur royal family and uma...</td>\n",
              "      <td>इनमें जोधपुर राजपरिवार और उम्मैद भवन के मालिक ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2505</th>\n",
              "      <td>ln mittal sachin tendulkar and bollywood actor...</td>\n",
              "      <td>एलएनमित्तल सचिन तेंदुलकर फिल्म अभिनेता अनिल कप...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2506</th>\n",
              "      <td>chartered planes have been booked to ferry the...</td>\n",
              "      <td>मेहमानों को लानेले जाने के लिए चार्टर्ड विमानो...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2507 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed2fb9b7-a2c5-4e9e-9fba-458fb7cf2a14')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ed2fb9b7-a2c5-4e9e-9fba-458fb7cf2a14 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ed2fb9b7-a2c5-4e9e-9fba-458fb7cf2a14');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                english  \\\n",
              "0                               a black box in your car   \n",
              "1     as americas road planners struggle to find the...   \n",
              "2     the devices which track every mile a motorist ...   \n",
              "3     the usually dull arena of highway planning has...   \n",
              "4     libertarians have joined environmental groups ...   \n",
              "...                                                 ...   \n",
              "2502  it is noteworthy that both nita and isha are p...   \n",
              "2503         vips have been invited to this royal party   \n",
              "2504  these include the jodhpur royal family and uma...   \n",
              "2505  ln mittal sachin tendulkar and bollywood actor...   \n",
              "2506  chartered planes have been booked to ferry the...   \n",
              "\n",
              "                                                  hindi  \n",
              "0                              आपकी कार में ब्लैक बॉक्स  \n",
              "1     जबकि अमेरिका के सड़क योजनाकार ध्वस्त होते हुए ...  \n",
              "2     यह डिवाइस जो मोटरचालक द्वारा वाहन चलाए गए प्रत...  \n",
              "3     आम तौर पर हाईवे नियोजन जैसा उबाऊ काम भी अचानक ...  \n",
              "4     आपने द्वारा ड्राइव किए गए मील तथा संभवतः ड्राइ...  \n",
              "...                                                 ...  \n",
              "2502  गौरतलब है कि नीता और ईशा दोनों ही प्रोफेशनल क्...  \n",
              "2503  इस शाही पार्टी के लिए वीवीआईपी लोगों को भी आमं...  \n",
              "2504  इनमें जोधपुर राजपरिवार और उम्मैद भवन के मालिक ...  \n",
              "2505  एलएनमित्तल सचिन तेंदुलकर फिल्म अभिनेता अनिल कप...  \n",
              "2506  मेहमानों को लानेले जाने के लिए चार्टर्ड विमानो...  \n",
              "\n",
              "[2507 rows x 2 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Glove Vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "using 300-dim Glove word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-NWoOh0e6di",
        "outputId": "64f5525b-4a8f-48c6-e939-1b41ed9dc894"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-04-07 11:41:36--  http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.840B.300d.zip [following]\n",
            "--2022-04-07 11:41:36--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",
            "--2022-04-07 11:41:36--  http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘glove.840B.300d.zip’\n",
            "\n",
            "glove.840B.300d.zip 100%[===================>]   2.03G  5.11MB/s    in 6m 50s  \n",
            "\n",
            "2022-04-07 11:48:26 (5.06 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n",
            "Archive:  glove.840B.300d.zip\n",
            "  inflating: glove.840B.300d.txt     \n",
            "GloVe data loaded\n"
          ]
        }
      ],
      "source": [
        "glove_emb = {}\n",
        "with open('glove.840B.300d.txt') as f:\n",
        "    for line in f:\n",
        "        values = line.split(' ')\n",
        "        # The first entry is the word\n",
        "        # The rest are vectors representing the embedding for the word\n",
        "        glove_emb[values[0]] = np.asarray(values[1:], dtype='float32')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "initializing unknown tokens\n",
        "\n",
        "words not found are assigned an unknown token\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UNK = np.random.random(300)\n",
        "SOS = np.random.random(300)\n",
        "EOS = np.random.random(300)\n",
        "\n",
        "glove_emb['sos'] = SOS\n",
        "glove_emb['eos'] = EOS\n",
        "\n",
        "print('GloVe data loaded')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLDwWzyPfleE"
      },
      "outputs": [],
      "source": [
        "emb_size = 300\n",
        "\n",
        "vocab_size_eng = len(lang_eng.word_to_index)+1\n",
        "eng_emb_matrix = np.zeros((vocab_size_eng, emb_size))\n",
        "for word, i in sorted(lang_eng.word_to_index.items(), key=lambda x: x[1]):\n",
        "    eng_emb_matrix[i] = glove_emb.get(word, UNK)\n",
        "\n",
        "vocab_size_hin = len(lang_hin.word_to_index)+1\n",
        "hin_emb_matrix = np.zeros((vocab_size_hin, emb_size))\n",
        "for word, i in sorted(lang_hin.word_to_index.items(), key=lambda x: x[1]):\n",
        "    hin_emb_matrix[i] = glove_emb.get(word, UNK)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sULBUR6ydzSh"
      },
      "outputs": [],
      "source": [
        "\n",
        "class RNN_Encoder(nn.Module):\n",
        "    def __init__(self, input_size, emb_size, hidden_size, n_layers=1, bidirectional=True, batch_size=1):\n",
        "        super(RNN_Encoder, self).__init__()\n",
        "        self.bidirectional = bidirectional\n",
        "        self.hidden_size = int(hidden_size/2)\n",
        "        self.hidden_dim = self.hidden_size\n",
        "        self.num_layers = n_layers\n",
        "        self.batch_size = batch_size\n",
        "        self.embedding = nn.Embedding.from_pretrained(\n",
        "            torch.FloatTensor(eng_emb_matrix), freeze=True)\n",
        "        self.lstm = nn.LSTM(emb_size, self.hidden_size,\n",
        "                            n_layers*2, bidirectional=bidirectional)\n",
        "        self.linear = nn.Linear(hidden_size * 2, 1)\n",
        "\n",
        "    def forward(self, input, hidden=None):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output, (hidden, cell) = self.lstm(embedded, hidden)\n",
        "        fwd_final = hidden[0:hidden.size(0):2]\n",
        "        bwd_final = hidden[1:hidden.size(0):2]\n",
        "        final = torch.cat([fwd_final, bwd_final], dim=2)\n",
        "        return output, final\n",
        "\n",
        "    def initHidden(self):\n",
        "        directions = 2 if self.bidirectional else 1\n",
        "        return torch.zeros(\n",
        "            self.num_layers*2,\n",
        "            self.batch_size,\n",
        "            self.hidden_size*2,\n",
        "            device=device\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwT13-rohQ5z"
      },
      "outputs": [],
      "source": [
        "class RNN_AttnDecoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.2, max_length=hindi_lang.n_words,n_layers=1):\n",
        "        super(RNN_AttnDecoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p/5\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(hin_emb_matrix), freeze=True)\n",
        "        # self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn1 = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size, n_layers*2)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, enc):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        intmd_torch = torch.cat((embedded[0],hidden[0]),1)\n",
        "        attn_out= self.attn1(intmd_torch)\n",
        "        attn_weights = F.softmax(attn_out)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 enc_ops.unsqueeze(0))\n",
        "       \n",
        "        output = torch.cat((embedded, attn_applied), 0)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "        output = F.relu(output)\n",
        "        output = torch.squeeze(output,0)\n",
        "        dec_hidden = self.initHidden()\n",
        "        dec_cell = self.initCell()\n",
        "        output1, (dec_hidden, dec_cell) = self.lstm(output, (hidden, dec_cell))\n",
        "        output2 = F.log_softmax(self.out(output1[0]), dim=1)\n",
        "        return output2, dec_hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1*2, 1, self.hidden_size, device=device)\n",
        "\n",
        "    def initCell(self):\n",
        "        return torch.zeros(1*2, 1, self.hidden_size, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuE5C0pJignX"
      },
      "outputs": [],
      "source": [
        "\n",
        "def idx_from_sent(lang, sentence):\n",
        "    return [lang.word_to_index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensor_from_sent(lang, sentence):\n",
        "    indexes = idx_from_sent(lang, sentence)\n",
        "    indexes.append(token_EOS)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensor_from_pair(pair):\n",
        "    return (tensor_from_sent(lang_eng, pair[0]), tensor_from_sent(lang_hin, pair[1]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXdbPelFkmwQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "tf_ratio = 1\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, enc_op, decoder_optimizer, criterion, max_length=lang_hin.n_words):\n",
        "    enc_hidden = encoder.initHidden()\n",
        "\n",
        "    enc_op.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    ip_len = input_tensor.size(0)\n",
        "    target_len = target_tensor.size(0)\n",
        "\n",
        "    enc_ops = torch.zeros(\n",
        "        max_length, encoder.hidden_dim*2, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(ip_len):\n",
        "        enc_op, enc_hidden = encoder(input_tensor[ei])\n",
        "        enc_ops[ei] = enc_op[0, 0]\n",
        "\n",
        "    dec_ip = torch.tensor([[token_SOS]], device=device)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    tf_flag = True if random.random() < tf_ratio else False\n",
        "    # Teacher forcing: Feed the target as the next input\n",
        "    # Else: use its own predictions as the next input\n",
        "    if tf_flag:\n",
        "        for di in range(target_len):\n",
        "            dec_op, dec_hidden, decoder_attention = decoder(\n",
        "                dec_ip, dec_hidden, enc_ops)\n",
        "            loss += criterion(dec_op, target_tensor[di])\n",
        "            dec_ip = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        for di in range(target_len):\n",
        "            dec_op, dec_hidden, decoder_attention = decoder(\n",
        "                dec_ip, dec_hidden, enc_ops)\n",
        "            topv, topi = dec_op.topk(1)\n",
        "            # detach from history as input\n",
        "            dec_ip = topi.squeeze().detach()\n",
        "\n",
        "            loss += criterion(dec_op, target_tensor[di])\n",
        "            if dec_ip.item() == token_EOS:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    enc_op.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_len\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWJNeagfkupE"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def train_iter(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    loss_plot = []\n",
        "    tot_loss_disp = 0  # Reset every print_every\n",
        "    tot_loss_plot = 0  # Reset every plot_every\n",
        "    \n",
        "    enc_op = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    \n",
        "    random.shuffle(train_pair)\n",
        "    \n",
        "    criterion = nn.NLLLoss()\n",
        "    \n",
        "    for iter in range(0, len(train_pair)*2 + 1):\n",
        "        train_pairs = tensor_from_pair(train_pair[(iter)%len(train_pair)])\n",
        "        train_pair = train_pairs\n",
        "        input_tensor = train_pair[0]\n",
        "        target_tensor = train_pair[1]\n",
        "        \n",
        "        loss = train(input_tensor, target_tensor, encoder, decoder, enc_op, decoder_optimizer, criterion)\n",
        "        tot_loss_disp += loss\n",
        "        tot_loss_plot += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = tot_loss_disp / print_every\n",
        "            tot_loss_disp = 0\n",
        "            print('%.4f' % (print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = tot_loss_plot / plot_every\n",
        "            loss_plot.append(plot_loss_avg)\n",
        "            tot_loss_plot = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YsPHQq2k2lN"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def evaluate(encoder, decoder, sentence, max_length=lang_hin.n_words):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensor_from_sent(lang_eng, sentence)\n",
        "        ip_len = input_tensor.size()[0]\n",
        "        enc_ops = torch.zeros(max_length, encoder.hidden_dim*2, device=device)\n",
        "        \n",
        "        for ei in range(ip_len):\n",
        "            enc_op, enc_hidden = encoder(input_tensor[ei])\n",
        "            enc_ops[ei] += enc_op[0, 0]\n",
        "\n",
        "        dec_ip = torch.tensor([[token_SOS]], device=device)\n",
        "        \n",
        "        dec_hidden = enc_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "        \n",
        "        for di in range(max_length):\n",
        "            dec_op, dec_hidden, decoder_attention = decoder(\n",
        "                dec_ip, dec_hidden, enc_ops)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = dec_op.data.topk(1)\n",
        "            if topi.item() == token_EOS:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(lang_hin.index_to_word[topi.item()])\n",
        "\n",
        "            dec_ip = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0FaLgCjk8jG"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def rand_eval(encoder, decoder, n=20):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(test_pair)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        owds, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        op_sent = ' '.join(op_words)\n",
        "        print('<', op_sent)\n",
        "        print('')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cNG424VlAsT"
      },
      "outputs": [],
      "source": [
        "\n",
        "emb_dim = 300\n",
        "hidden_size = emb_dim\n",
        "hidden_dim = emb_dim\n",
        "n_layers = 1\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "encoder1 = RNN_Encoder(lang_eng.n_words, emb_dim, hidden_dim, n_layers).to(device)\n",
        "attn_decoder1 = RNN_AttnDecoder(emb_dim, lang_hin.n_words, n_layers).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEgNIOXElC4l",
        "outputId": "36979d1e-78e8-453f-b4b2-07b3ff5c5716"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0019\n",
            "5.8510\n",
            "5.3962\n",
            "5.3082\n",
            "5.2628\n",
            "5.2234\n",
            "5.2242\n",
            "5.1857\n",
            "5.1863\n",
            "5.1355\n",
            "5.1481\n",
            "5.1523\n",
            "5.1255\n",
            "5.1040\n",
            "5.0991\n",
            "5.0802\n",
            "5.1000\n",
            "5.0764\n",
            "5.0903\n",
            "5.0480\n",
            "5.0666\n"
          ]
        }
      ],
      "source": [
        "train_iter(encoder1, attn_decoder1, 100, print_every=5000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSJdv2wileHR",
        "outputId": "b09445cf-a519-41a4-8a7e-97d5ad6649d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ],
      "source": [
        "actual, predicted = [], []\n",
        "for i in range(len(test_pair)):\n",
        "    pair = test_pair[i]\n",
        "    op_words, attentions = evaluate(encoder1, attn_decoder1, pair[0])\n",
        "    op_sent = ' '.join(op_words)\n",
        "\n",
        "    ls_hin = pair[1].split()\n",
        "    pred_sen = op_sent.split()\n",
        "\n",
        "    if (ls_hin[-1] == \"<EOS>\"):\n",
        "        ls_hin = ls_hin[:-1]\n",
        "\n",
        "    if (ls_hin[0] == \"<SOS>\"):\n",
        "        ls_hin.pop(0)\n",
        "\n",
        "    if (pred_sen[-1] == \"<EOS>\"):\n",
        "        pred_sen = pred_sen[:-1]\n",
        "\n",
        "    actual.append(ls_hin)\n",
        "    predicted.append(pred_sen)\n",
        "\n",
        "bleu_score = corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0))\n",
        "print(\"==================================\")\n",
        "print(\"Bleu Score: \", round(bleu_score, 4))\n",
        "print(\"==================================\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHfLbQ9siGI-",
        "outputId": "01e244af-01c2-4745-8239-41cab64fa822"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bleu Score:  0.3272401269530751\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-O-KWX8_iNWk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "1701CS19_assignment05.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "2b38c7d7b3882d4b51b84281967909c1a9e01b716d41235b6b2aa71cdf5650ce"
    },
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
