{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from collections import Counter\n",
    "# Importing torch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "names = iris['target_names']\n",
    "feature_names = iris['feature_names']\n",
    "\n",
    "# Scale data to have mean 0 and variance 1 \n",
    "# which is importance for convergence of the neural network\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_scaled.shape)\n",
    "print(y.shape)\n",
    "len(y==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 50, 1: 50, 2: 50})\n",
      "train_size {0: 40, 1: 40, 2: 40}\n"
     ]
    }
   ],
   "source": [
    "# Splitting into train and test\n",
    "count_dict = Counter(y)\n",
    "print(count_dict)\n",
    "train_size = {}\n",
    "for key, value in count_dict.items():\n",
    "    train_size[key] = int(value*0.8)\n",
    "print('train_size', train_size)\n",
    "train_X, train_y = [], []\n",
    "test_X, test_y = [], []\n",
    "for data, label in zip(X_scaled, y):\n",
    "    if train_size[label] >0:\n",
    "        train_X.append(data)\n",
    "        train_y.append(label)\n",
    "        train_size[label] = train_size[label]-1\n",
    "    else:\n",
    "        test_X.append(data)\n",
    "        test_y.append(label)\n",
    "X_train, y_train = np.array(train_X), np.array(train_y)\n",
    "X_test, y_test = np.array(test_X), np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (120, 4) (120,)\n",
      "Test shape (30, 4) (30,)\n"
     ]
    }
   ],
   "source": [
    "print('Train shape', X_train.shape, y_train.shape)\n",
    "print('Test shape', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Setting hyper-parameters\n",
    "input_size = X_train.shape[1] # 28x28\n",
    "hidden_size = [32,64,128,256,512,1024] \n",
    "num_classes = 3\n",
    "num_epochs = 15\n",
    "batch_size = 32\n",
    "learning_rate = 0.001 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the dataloader\n",
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(X_train), torch.tensor(y_train, dtype=torch.long)),\n",
    "                                            batch_size=batch_size, \n",
    "                                            shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(X_test), torch.tensor(y_test, dtype=torch.long)),\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Neural Model\n",
    "class singleMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super(singleMLP, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.l1 = nn.Linear(input_dim, hidden_dim) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_dim, num_classes)   \n",
    "    def forward(self, x):\n",
    "            out = self.l1(x)\n",
    "            out = self.relu(out)\n",
    "            out = self.l2(out)\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the device\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "model = singleMLP(input_size, hidden_size[0], num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the loss and the optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Step[1/4], Loss: 1.1040\n",
      "Epoch [1/15], Step[2/4], Loss: 1.0940\n",
      "Epoch [1/15], Step[3/4], Loss: 1.0726\n",
      "Epoch [1/15], Step[4/4], Loss: 1.0877\n",
      "Epoch [2/15], Step[1/4], Loss: 1.0776\n",
      "Epoch [2/15], Step[2/4], Loss: 1.0779\n",
      "Epoch [2/15], Step[3/4], Loss: 1.0196\n",
      "Epoch [2/15], Step[4/4], Loss: 1.0725\n",
      "Epoch [3/15], Step[1/4], Loss: 1.0272\n",
      "Epoch [3/15], Step[2/4], Loss: 1.0568\n",
      "Epoch [3/15], Step[3/4], Loss: 1.0093\n",
      "Epoch [3/15], Step[4/4], Loss: 1.0404\n",
      "Epoch [4/15], Step[1/4], Loss: 0.9857\n",
      "Epoch [4/15], Step[2/4], Loss: 1.0155\n",
      "Epoch [4/15], Step[3/4], Loss: 1.0156\n",
      "Epoch [4/15], Step[4/4], Loss: 1.0064\n",
      "Epoch [5/15], Step[1/4], Loss: 0.9808\n",
      "Epoch [5/15], Step[2/4], Loss: 0.9648\n",
      "Epoch [5/15], Step[3/4], Loss: 0.9945\n",
      "Epoch [5/15], Step[4/4], Loss: 0.9717\n",
      "Epoch [6/15], Step[1/4], Loss: 0.9047\n",
      "Epoch [6/15], Step[2/4], Loss: 0.9870\n",
      "Epoch [6/15], Step[3/4], Loss: 0.9724\n",
      "Epoch [6/15], Step[4/4], Loss: 0.9360\n",
      "Epoch [7/15], Step[1/4], Loss: 0.8885\n",
      "Epoch [7/15], Step[2/4], Loss: 0.9514\n",
      "Epoch [7/15], Step[3/4], Loss: 0.9221\n",
      "Epoch [7/15], Step[4/4], Loss: 0.9377\n",
      "Epoch [8/15], Step[1/4], Loss: 0.9266\n",
      "Epoch [8/15], Step[2/4], Loss: 0.9134\n",
      "Epoch [8/15], Step[3/4], Loss: 0.8190\n",
      "Epoch [8/15], Step[4/4], Loss: 0.9387\n",
      "Epoch [9/15], Step[1/4], Loss: 0.8554\n",
      "Epoch [9/15], Step[2/4], Loss: 0.9130\n",
      "Epoch [9/15], Step[3/4], Loss: 0.7849\n",
      "Epoch [9/15], Step[4/4], Loss: 0.9517\n",
      "Epoch [10/15], Step[1/4], Loss: 0.8703\n",
      "Epoch [10/15], Step[2/4], Loss: 0.8094\n",
      "Epoch [10/15], Step[3/4], Loss: 0.8965\n",
      "Epoch [10/15], Step[4/4], Loss: 0.7873\n",
      "Epoch [11/15], Step[1/4], Loss: 0.7972\n",
      "Epoch [11/15], Step[2/4], Loss: 0.8177\n",
      "Epoch [11/15], Step[3/4], Loss: 0.8279\n",
      "Epoch [11/15], Step[4/4], Loss: 0.8407\n",
      "Epoch [12/15], Step[1/4], Loss: 0.8075\n",
      "Epoch [12/15], Step[2/4], Loss: 0.7713\n",
      "Epoch [12/15], Step[3/4], Loss: 0.7551\n",
      "Epoch [12/15], Step[4/4], Loss: 0.8593\n",
      "Epoch [13/15], Step[1/4], Loss: 0.7628\n",
      "Epoch [13/15], Step[2/4], Loss: 0.8046\n",
      "Epoch [13/15], Step[3/4], Loss: 0.7499\n",
      "Epoch [13/15], Step[4/4], Loss: 0.7582\n",
      "Epoch [14/15], Step[1/4], Loss: 0.7448\n",
      "Epoch [14/15], Step[2/4], Loss: 0.7299\n",
      "Epoch [14/15], Step[3/4], Loss: 0.7718\n",
      "Epoch [14/15], Step[4/4], Loss: 0.7327\n",
      "Epoch [15/15], Step[1/4], Loss: 0.7363\n",
      "Epoch [15/15], Step[2/4], Loss: 0.7337\n",
      "Epoch [15/15], Step[3/4], Loss: 0.7204\n",
      "Epoch [15/15], Step[4/4], Loss: 0.6922\n"
     ]
    }
   ],
   "source": [
    "# Defining the training loop\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (features, labels) in enumerate(train_loader):\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(features.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 1 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step[{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 30 test features: 93.33333333333333 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "           2       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.94      0.93      0.93        30\n",
      "weighted avg       0.94      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "with torch.no_grad():\n",
    "    true_lables = []\n",
    "    predicted_labels = []\n",
    "    for features, labels in test_loader:\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(features.float())\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted_labels.extend(predicted)\n",
    "        true_lables.extend(labels)\n",
    "    accuracy = accuracy_score(true_lables, predicted_labels)*100\n",
    "    print(f'Accuracy of the network on the 30 test features: {accuracy} %')\n",
    "    print(classification_report(true_lables, predicted_labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimenting with hidden size value 32\n",
      "Accuracy of the network on the 30 test features: 83.33333333333334 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.78      0.70      0.74        10\n",
      "           2       0.73      0.80      0.76        10\n",
      "\n",
      "    accuracy                           0.83        30\n",
      "   macro avg       0.84      0.83      0.83        30\n",
      "weighted avg       0.84      0.83      0.83        30\n",
      "\n",
      "Experimenting with hidden size value 64\n",
      "Accuracy of the network on the 30 test features: 90.0 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       1.00      0.70      0.82        10\n",
      "           2       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.91      0.90      0.90        30\n",
      "weighted avg       0.91      0.90      0.90        30\n",
      "\n",
      "Experimenting with hidden size value 128\n",
      "Accuracy of the network on the 30 test features: 100.0 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Experimenting with hidden size value 256\n",
      "Accuracy of the network on the 30 test features: 96.66666666666667 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        10\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "Experimenting with hidden size value 512\n",
      "Accuracy of the network on the 30 test features: 96.66666666666667 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        10\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "Experimenting with hidden size value 1024\n",
      "Accuracy of the network on the 30 test features: 96.66666666666667 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        10\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NOTE; Experimenting with different values of hidden layers\n",
    "accuracies = []\n",
    "for hidden_size_val in hidden_size:\n",
    "    print('Experimenting with hidden size value', hidden_size_val)\n",
    "    # Creating the model\n",
    "    model = singleMLP(input_size, hidden_size_val, num_classes).to(device)\n",
    "    # Defining the loss and the optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    # Defining the training loop\n",
    "    n_total_steps = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (features, labels) in enumerate(train_loader):  \n",
    "            # origin shape: [100, 1, 28, 28]\n",
    "            # resized: [100, 784]\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Forward pass\n",
    "            outputs = model(features.float())\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (i+1) % 200 == 0:\n",
    "                print (f'Epoch [{epoch+1}/{num_epochs}], Step[{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "    # Testing the model\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        true_lables = []\n",
    "        predicted_labels = []\n",
    "        for features, labels in test_loader:\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(features.float())\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predicted_labels.extend(predicted)\n",
    "            true_lables.extend(labels)\n",
    "        accuracy = accuracy_score(true_lables, predicted_labels)*100\n",
    "        accuracies.append(accuracy)\n",
    "        print(f'Accuracy of the network on the 30 test features: {accuracy} %')\n",
    "        print(classification_report(true_lables, predicted_labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the trend of accuracy vs hidden_dim\n",
    "accuracy_df = pd.DataFrame()\n",
    "accuracy_df['hidden_sizes'] = hidden_size\n",
    "accuracy_df['accuracies'] = accuracies\n",
    "accuracy_df.plot(x=\"hidden_sizes\", y=\"accuracies\", kind=\"line\")\n",
    "plt.title('IRIS Dataset')\n",
    "plt.ylabel('Accuracies')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4905652b14e4b7eb92899b78ac499a22c488804455b27940a322fd82aaf71031"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
