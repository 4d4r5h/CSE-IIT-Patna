{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GwXocxPE9cds",
    "outputId": "add5d555-49fd-44dc-8b67-efc11cbc7ce6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sriram/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/sriram/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import collections\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "H2Clyqs59cdv"
   },
   "outputs": [],
   "source": [
    "with open('train_5500.label.txt', 'rb') as f:\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "q1qwRzzJ9cdw"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    temp = text.split(\":\")\n",
    "    label = temp[0][2:]\n",
    "    text = (\" \").join(temp[1].split()[1:])\n",
    "    text = re.sub(r\"@[A-Za-z0-9]+\", ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    text = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', text)\n",
    "    text = re.sub(r\"[^a-zA-z.!?'0-9]\", ' ', text)\n",
    "    text = re.sub('\\t', ' ',  text)\n",
    "    text = re.sub(r\" +\", ' ', text)\n",
    "    return(text[:-2].lower(), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ge4QAl5k9cdw"
   },
   "outputs": [],
   "source": [
    "line = str(data[0])\n",
    "\n",
    "temp = line.split(\":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ytfDujKV9cdx",
    "outputId": "42859f66-8ed9-41b8-f8b6-b3d28d4ebd92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DESC'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[0][2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "wUEve0LE9cdy",
    "outputId": "4cd48160-f435-4ab6-a2b2-70f8f31f77c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"How did serfdom develop in and then leave Russia ?\\\\n'\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\" \").join(temp[1].split()[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "WJ_rtgvV9cdy"
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "for line in data:\n",
    "    sent, lab = clean_text(str(line))\n",
    "    X_train.append(sent)\n",
    "    Y_train.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "JlN6PcJB9cdz",
    "outputId": "3bb87d1f-114a-471f-e2b9-a33e2d8c7695"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DESC'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-hhpjqnR9cdz"
   },
   "outputs": [],
   "source": [
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Emm1V5nq9cd0"
   },
   "outputs": [],
   "source": [
    "def generate_N_grams(words,ngram=1, freq=500): \n",
    "    res= ngrams(words,ngram)\n",
    "    mostFreq = collections.Counter(res)\n",
    "    ans=mostFreq.most_common(freq)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zsSGEcgV9cd0"
   },
   "outputs": [],
   "source": [
    "words= []\n",
    "data = []\n",
    "length=[]\n",
    "lexical=[]\n",
    "syntactic = []\n",
    "for sent, label in zip(X_train, Y_train):\n",
    "    data.append(sent)\n",
    "    length.append(len(sent.split()))\n",
    "    words.extend([word for word in sent.split(\" \") if word not in set(stopwords.words('english'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XPmqG1lT9cd0"
   },
   "outputs": [],
   "source": [
    "top_ngrams = [w[0][0] for w in generate_N_grams(words,1,500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "GmpUnGHHCCZx"
   },
   "outputs": [],
   "source": [
    "for sent, label in zip(X_train, Y_train):\n",
    "    wordlist = [word for word in sent.split(\" \") if word in top_ngrams]\n",
    "    lexical.append(wordlist)\n",
    "    syntactic.append(nltk.pos_tag(wordlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(lexical[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "RPJAyeK89eyP",
    "outputId": "70ccaa62-c94d-423c-8016-a7d3cf42a63a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>length</th>\n",
       "      <th>lexical</th>\n",
       "      <th>syntactic</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how did serfdom develop in and then leave russia</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DESC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what films featured the character popeye doyle</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ENTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how can i find a list of celebrities real names</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>DESC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what fowl grabs the spotlight after the chines...</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ENTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the full form of com</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ABBR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  length  lexical  \\\n",
       "0   how did serfdom develop in and then leave russia       9        0   \n",
       "1     what films featured the character popeye doyle       7        2   \n",
       "2    how can i find a list of celebrities real names      10        4   \n",
       "3  what fowl grabs the spotlight after the chines...      12        2   \n",
       "4                       what is the full form of com       7        2   \n",
       "\n",
       "   syntactic label  \n",
       "0          0  DESC  \n",
       "1          2  ENTY  \n",
       "2          4  DESC  \n",
       "3          2  ENTY  \n",
       "4          2  ABBR  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df['sentence']=data\n",
    "df['length']=length\n",
    "# df['lexical']=lexical\n",
    "df['lexical']=[len(x) for x in lexical]\n",
    "# df['syntactic']=syntactic\n",
    "df['syntactic']=[len(x) for x in syntactic]\n",
    "df['label'] = Y_train\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Hff13P49cd1",
    "outputId": "76f42798-8d68-4f2d-d248-19e50a19bffa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9126174998075649"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gini_impurity(y):\n",
    "    '''\n",
    "    Given a Pandas Series, it calculates the Gini Impurity. \n",
    "    y: variable with which calculate Gini Impurity.\n",
    "    '''\n",
    "    if isinstance(y, pd.Series):\n",
    "        p = y.value_counts()/y.shape[0]\n",
    "        gini = 1-np.sum(p**2)\n",
    "        return(gini)\n",
    "\n",
    "    else:\n",
    "        raise('Object must be a Pandas Series.')\n",
    "\n",
    "gini_impurity(df.length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ByggkGfU9cd1",
    "outputId": "36e32d9a-a38c-4848-8929-632bc784ff46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.765096214502992"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entropy(y):\n",
    "    '''\n",
    "    Given a Pandas Series, it calculates the entropy. \n",
    "    y: variable with which calculate entropy.\n",
    "    '''\n",
    "    if isinstance(y, pd.Series):\n",
    "        a = y.value_counts()/y.shape[0]\n",
    "        entropy = np.sum(-a*np.log2(a+1e-9))\n",
    "        return(entropy)\n",
    "\n",
    "    else:\n",
    "        raise('Object must be a Pandas Series.')\n",
    "\n",
    "entropy(df.length)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(y):\n",
    "    '''\n",
    "    Function to help calculate the variance avoiding nan.\n",
    "    y: variable to calculate variance to. It should be a Pandas Series.\n",
    "    '''\n",
    "    if(len(y) == 1):\n",
    "        return 0\n",
    "    else:\n",
    "        return y.var()\n",
    "\n",
    "def information_gain(y, mask, func=entropy):\n",
    "    '''\n",
    "    It returns the Information Gain of a variable given a loss function.\n",
    "    y: target variable.\n",
    "    mask: split choice.\n",
    "    func: function to be used to calculate Information Gain in case os classification.\n",
    "    '''\n",
    "\n",
    "    a = sum(mask)\n",
    "    b = mask.shape[0] - a\n",
    "\n",
    "    if(a == 0 or b ==0): \n",
    "        ig = 0\n",
    "\n",
    "    else:\n",
    "        if y.dtypes != 'O':\n",
    "            ig = variance(y) - (a/(a+b)* variance(y[mask])) - (b/(a+b)*variance(y[-mask]))\n",
    "        else:\n",
    "            ig = func(y)-a/(a+b)*func(y[mask])-b/(a+b)*func(y[-mask])\n",
    "\n",
    "    return ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "31Wp5-kN9cd1"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def categorical_options(a):\n",
    "    '''\n",
    "    Creates all possible combinations from a Pandas Series.\n",
    "    a: Pandas Series from where to get all possible combinations. \n",
    "    '''\n",
    "    a = a.unique()\n",
    "\n",
    "    opciones = []\n",
    "    for L in range(0, len(a)+1):\n",
    "        for subset in itertools.combinations(a, L):\n",
    "            subset = list(subset)\n",
    "            opciones.append(subset)\n",
    "\n",
    "    return opciones[1:-1]\n",
    "\n",
    "def max_information_gain_split(x, y, func=entropy):\n",
    "    '''\n",
    "    Given a predictor & target variable, returns the best split, the error and the type of variable based on a selected cost function.\n",
    "    x: predictor variable as Pandas Series.\n",
    "    y: target variable as Pandas Series.\n",
    "    func: function to be used to calculate the best split.\n",
    "    '''\n",
    "\n",
    "    split_value = []\n",
    "    ig = [] \n",
    "\n",
    "    numeric_variable = True if x.dtypes != 'O' else False\n",
    "\n",
    "    # Create options according to variable type\n",
    "    if numeric_variable:\n",
    "        options = x.sort_values().unique()[1:]\n",
    "    else: \n",
    "        options = categorical_options(x)\n",
    "\n",
    "    # Calculate ig for all values\n",
    "    for val in options:\n",
    "        mask =   x < val if numeric_variable else x.isin(val)\n",
    "        val_ig = information_gain(y, mask, func)\n",
    "        # Append results\n",
    "        ig.append(val_ig)\n",
    "        split_value.append(val)\n",
    "\n",
    "    # Check if there are more than 1 results if not, return False\n",
    "    if len(ig) == 0:\n",
    "        return(None,None,None, False)\n",
    "\n",
    "    else:\n",
    "        # Get results with highest IG\n",
    "        best_ig = max(ig)\n",
    "        best_ig_index = ig.index(best_ig)\n",
    "        best_split = split_value[best_ig_index]\n",
    "        return(best_ig,best_split,numeric_variable, True)\n",
    "\n",
    "\n",
    "    weight_ig, weight_slpit, _, _ = max_information_gain_split(df['length'], df['label'],)  \n",
    "\n",
    "\n",
    "    print(\n",
    "    \"The best split for Weight is when the variable is less than \",\n",
    "    weight_slpit,\"\\nInformation Gain for that split is:\", weight_ig\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "4WKZ3K4nGwiB"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>lexical</th>\n",
       "      <th>syntactic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054908</td>\n",
       "      <td>0.056198</td>\n",
       "      <td>0.056198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     length   lexical syntactic\n",
       "0  0.054908  0.056198  0.056198\n",
       "1         6         2         2\n",
       "2      True      True      True\n",
       "3      True      True      True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['label', 'sentence'], axis= 1).apply(max_information_gain_split, y = df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "n5ozWnEBG0YJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05490794663614973, 6, True, True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_information_gain_split(x=df[\"length\"], y=df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05619806339625466, 2, True, True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_information_gain_split(x=df[\"lexical\"], y=df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_split(y, data):\n",
    "    '''\n",
    "    Given a data, select the best split and return the variable, the value, the variable type and the information gain.\n",
    "    y: name of the target variable\n",
    "    data: dataframe where to find the best split.\n",
    "    '''\n",
    "    masks = data.drop(y, axis= 1).apply(max_information_gain_split, y = data[y])\n",
    "    if sum(masks.loc[3,:]) == 0:\n",
    "        return(None, None, None, None)\n",
    "\n",
    "    else:\n",
    "        # Get only masks that can be splitted\n",
    "        masks = masks.loc[:,masks.loc[3,:]]\n",
    "\n",
    "        # Get the results for split with highest IG\n",
    "        split_variable = max(masks)\n",
    "        #split_valid = masks[split_variable][]\n",
    "        split_value = masks[split_variable][1] \n",
    "        split_ig = masks[split_variable][0]\n",
    "        split_numeric = masks[split_variable][2]\n",
    "\n",
    "    return(split_variable, split_value, split_ig, split_numeric)\n",
    "\n",
    "\n",
    "def make_split(variable, value, data, is_numeric):\n",
    "    '''\n",
    "    Given a data and a split conditions, do the split.\n",
    "    variable: variable with which make the split.\n",
    "    value: value of the variable to make the split.\n",
    "    data: data to be splitted.\n",
    "    is_numeric: boolean considering if the variable to be splitted is numeric or not.\n",
    "    '''\n",
    "    if is_numeric:\n",
    "        data_1 = data[data[variable] < value]\n",
    "        data_2 = data[(data[variable] < value) == False]\n",
    "\n",
    "    else:\n",
    "        data_1 = data[data[variable].isin(value)]\n",
    "        data_2 = data[(data[variable].isin(value)) == False]\n",
    "\n",
    "    return(data_1,data_2)\n",
    "\n",
    "def make_prediction(data, target_factor):\n",
    "    '''\n",
    "    Given the target variable, make a prediction.\n",
    "    data: pandas series for target variable\n",
    "    target_factor: boolean considering if the variable is a factor or not\n",
    "    '''\n",
    "\n",
    "    # Make predictions\n",
    "    if target_factor:\n",
    "        pred = data.value_counts().idxmax()\n",
    "    else:\n",
    "        pred = data.mean()\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dtypes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-d450155867b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m \u001b[0mdecisiones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'obese'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_information_gain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-d450155867b7>\u001b[0m in \u001b[0;36mtrain_tree\u001b[0;34m(data, y, target_factor, max_depth, min_samples_split, min_information_gain, counter, max_categories)\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;31m# Check that max_categories is fulfilled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mcheck_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"object\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'dtypes'"
     ]
    }
   ],
   "source": [
    "def train_tree(data,y, target_factor, max_depth = None,min_samples_split = None, min_information_gain = 1e-20, counter=0, max_categories = 20):\n",
    "  '''\n",
    "  Trains a Decission Tree\n",
    "  data: Data to be used to train the Decission Tree\n",
    "  y: target variable column name\n",
    "  target_factor: boolean to consider if target variable is factor or numeric.\n",
    "  max_depth: maximum depth to stop splitting.\n",
    "  min_samples_split: minimum number of observations to make a split.\n",
    "  min_information_gain: minimum ig gain to consider a split to be valid.\n",
    "  max_categories: maximum number of different values accepted for categorical values. High number of values will slow down learning process. R\n",
    "  '''\n",
    "\n",
    "  # Check that max_categories is fulfilled\n",
    "  if counter==0:\n",
    "    types = data.dtypes\n",
    "    check_columns = types[types == \"object\"].index\n",
    "    for column in check_columns:\n",
    "      var_length = len(data[column].value_counts()) \n",
    "      if var_length > max_categories:\n",
    "        raise ValueError('The variable ' + column + ' has '+ str(var_length) + ' unique values, which is more than the accepted ones: ' +  str(max_categories))\n",
    "\n",
    "  # Check for depth conditions\n",
    "  if max_depth == None:\n",
    "    depth_cond = True\n",
    "\n",
    "  else:\n",
    "    if counter < max_depth:\n",
    "      depth_cond = True\n",
    "\n",
    "    else:\n",
    "      depth_cond = False\n",
    "\n",
    "  # Check for sample conditions\n",
    "  if min_samples_split == None:\n",
    "    sample_cond = True\n",
    "\n",
    "  else:\n",
    "    if data.shape[0] > min_samples_split:\n",
    "      sample_cond = True\n",
    "\n",
    "    else:\n",
    "      sample_cond = False\n",
    "\n",
    "  # Check for ig condition\n",
    "  if depth_cond & sample_cond:\n",
    "\n",
    "    var,val,ig,var_type = get_best_split(y, data)\n",
    "\n",
    "    # If ig condition is fulfilled, make split \n",
    "    if ig is not None and ig >= min_information_gain:\n",
    "\n",
    "      counter += 1\n",
    "\n",
    "      left,right = make_split(var, val, data,var_type)\n",
    "\n",
    "      # Instantiate sub-tree\n",
    "      split_type = \"<=\" if var_type else \"in\"\n",
    "      question =   \"{} {}  {}\".format(var,split_type,val)\n",
    "      # question = \"\\n\" + counter*\" \" + \"|->\" + var + \" \" + split_type + \" \" + str(val) \n",
    "      subtree = {question: []}\n",
    "\n",
    "\n",
    "      # Find answers (recursion)\n",
    "      yes_answer = train_tree(left,y, target_factor, max_depth,min_samples_split,min_information_gain, counter)\n",
    "\n",
    "      no_answer = train_tree(right,y, target_factor, max_depth,min_samples_split,min_information_gain, counter)\n",
    "\n",
    "      if yes_answer == no_answer:\n",
    "        subtree = yes_answer\n",
    "\n",
    "      else:\n",
    "        subtree[question].append(yes_answer)\n",
    "        subtree[question].append(no_answer)\n",
    "\n",
    "    # If it doesn't match IG condition, make prediction\n",
    "    else:\n",
    "      pred = make_prediction(data[y],target_factor)\n",
    "      return pred\n",
    "\n",
    "   # Drop dataset if doesn't match depth or sample conditions\n",
    "  else:\n",
    "    pred = make_prediction(data[y],target_factor)\n",
    "    return pred\n",
    "\n",
    "  return subtree\n",
    "\n",
    "\n",
    "max_depth = 5\n",
    "min_samples_split = 20\n",
    "min_information_gain  = 1e-5\n",
    "\n",
    "\n",
    "decisiones = train_tree(data,'obese',True, max_depth,min_samples_split,min_information_gain)\n",
    "\n",
    "\n",
    "decisiones"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
