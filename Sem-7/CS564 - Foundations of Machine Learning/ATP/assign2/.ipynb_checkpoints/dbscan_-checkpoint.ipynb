{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "### Foundations of Machine Learning (CS564)\n",
    "\n",
    "### *DBSCAN Algorithm*\n",
    "\n",
    "<table style=\"font-size:15px\">\n",
    "    <thead>\n",
    "        <td><b>Name of Student</b></td>\n",
    "        <td><b>Roll No.</b></td>\n",
    "        <td><b>Date</b></td>\n",
    "    </thead>\n",
    "    <tr>\n",
    "        <td>M. Maheeth Reddy</td>\n",
    "        <td>1801CS31</td>\n",
    "        <td>01-Sep-2021</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "**NOTE**: I used SciPy library only for reading the dataset and nothing else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io.arff import loadarff \n",
    "\n",
    "import math\n",
    "\n",
    "eps = 2\n",
    "minPts = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from arff file to DataFrame\n",
    "raw_data = loadarff('diabetes1.arff')\n",
    "df_data = pd.DataFrame(raw_data[0])\n",
    "\n",
    "# fill NaN values with mode\n",
    "df_data.fillna(df_data.mode().iloc[0], inplace=True)\n",
    "\n",
    "# drop the last column as mentioned in assignment\n",
    "df_data.drop(['class'],axis=1,inplace=True)\n",
    "\n",
    "# normalize the data\n",
    "df_data=(df_data-df_data.mean())/(df_data.std())\n",
    "\n",
    "# show some rows in the data\n",
    "df_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data.to_numpy()\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Utility Functions\n",
    "def euclidean_distance(x1, x2):\n",
    "    \"\"\" Calculates the l2 distance between two vectors \"\"\"\n",
    "    distance = 0\n",
    "    # Squared distance between each coordinate\n",
    "    for i in range(len(x1)):\n",
    "        distance += pow((x1[i] - x2[i]), 2)\n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "class DBSCAN():\n",
    "    \"\"\"A density based clustering method that expands clusters from \n",
    "    samples that have more neighbors within a radius specified by eps\n",
    "    than the value min_samples.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    eps: float\n",
    "        The radius within which samples are considered neighbors\n",
    "    min_samples: int\n",
    "        The number of neighbors required for the sample to be a core point. \n",
    "    \"\"\"\n",
    "    def __init__(self, eps=1, min_samples=5):\n",
    "        self.eps = eps\n",
    "        self.min_samples = min_samples\n",
    "\n",
    "    def _get_neighbors(self, sample_i):\n",
    "        \"\"\" Return a list of indexes of neighboring samples\n",
    "        A sample_2 is considered a neighbor of sample_1 if the distance between\n",
    "        them is smaller than epsilon \"\"\"\n",
    "        neighbors = []\n",
    "        idxs = np.arange(len(self.X))\n",
    "        for i, _sample in enumerate(self.X[idxs != sample_i]):\n",
    "            distance = euclidean_distance(self.X[sample_i], _sample)\n",
    "            if distance < self.eps:\n",
    "                neighbors.append(i)\n",
    "        return np.array(neighbors)\n",
    "\n",
    "    def _expand_cluster(self, sample_i, neighbors, core_points, border_points):\n",
    "        \"\"\" Recursive method which expands the cluster until we have reached the border\n",
    "        of the dense area (density determined by eps and min_samples) \"\"\"\n",
    "        cluster = [sample_i]\n",
    "        # Iterate through neighbors\n",
    "        for neighbor_i in neighbors:\n",
    "            if not neighbor_i in self.visited_samples:\n",
    "                self.visited_samples.append(neighbor_i)\n",
    "                # Fetch the sample's distant neighbors (neighbors of neighbor)\n",
    "                self.neighbors[neighbor_i] = self._get_neighbors(neighbor_i)\n",
    "                # Make sure the neighbor's neighbors are more than min_samples\n",
    "                # (If this is true the neighbor is a core point)\n",
    "                if len(self.neighbors[neighbor_i]) >= self.min_samples:\n",
    "                    core_points.append(neighbor_i)\n",
    "                    # Expand the cluster from the neighbor\n",
    "                    expanded_cluster, core_points, border_points = self._expand_cluster(\n",
    "                        neighbor_i, self.neighbors[neighbor_i], core_points, border_points)\n",
    "                    # Add expanded cluster to this cluster\n",
    "                    cluster = cluster + expanded_cluster\n",
    "                else:\n",
    "                    # These will be Border Points\n",
    "                    # If the neighbor is not a core point we only add the neighbor point\n",
    "                    cluster.append(neighbor_i)\n",
    "                    border_points.append(neighbor_i)\n",
    "        return cluster, core_points, border_points\n",
    "\n",
    "    def _get_cluster_labels(self):\n",
    "        \"\"\" Return the samples labels as the index of the cluster in which they are\n",
    "        contained \"\"\"\n",
    "        # Set default value to number of clusters\n",
    "        # Will make sure all outliers have same cluster label\n",
    "        labels = np.full(shape=self.X.shape[0], fill_value=len(self.clusters))\n",
    "        for cluster_i, cluster in enumerate(self.clusters):\n",
    "            for sample_i in cluster:\n",
    "                labels[sample_i] = cluster_i\n",
    "        return labels\n",
    "\n",
    "    # DBSCAN\n",
    "    def predict(self, X):\n",
    "        self.X = X\n",
    "        self.clusters = []\n",
    "        self.core_points = []\n",
    "        self.border_points = []\n",
    "        self.visited_samples = []\n",
    "        self.neighbors = {}\n",
    "        n_samples = np.shape(self.X)[0]\n",
    "        # Iterate through samples and expand clusters from them\n",
    "        # if they have more neighbors than self.min_samples\n",
    "        for sample_i in range(n_samples):\n",
    "            if sample_i in self.visited_samples:\n",
    "                continue\n",
    "            self.neighbors[sample_i] = self._get_neighbors(sample_i)\n",
    "            if len(self.neighbors[sample_i]) >= self.min_samples:\n",
    "                # If core point => mark as visited\n",
    "                self.visited_samples.append(sample_i)\n",
    "                core_points = [sample_i]\n",
    "                border_points = []\n",
    "                # Sample has more neighbors than self.min_samples => expand\n",
    "                # cluster from sample\n",
    "                new_cluster, core_points, border_points = self._expand_cluster(\n",
    "                    sample_i, self.neighbors[sample_i], core_points, border_points)\n",
    "                # Add cluster to list of clusters\n",
    "                self.clusters.append(new_cluster)\n",
    "                self.core_points.append(core_points)\n",
    "                self.border_points.append(border_points)\n",
    "\n",
    "        # Get the resulting cluster labels\n",
    "        cluster_labels = self._get_cluster_labels()\n",
    "        return cluster_labels, self.core_points, self.border_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=2, min_samples=5)\n",
    "dbscan_out, final_core_points, final_border_points = dbscan.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters formed with labels are respective counts are:\n",
      "[0 1 2]\n",
      "[761   1   6]\n",
      "Cluster Lables [0 0 0 0 2 0 0 0 2 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(dbscan_out, return_counts=True)\n",
    "print(\"Clusters formed with labels are respective counts are:\")\n",
    "print(unique)\n",
    "print(counts)\n",
    "print('Cluster Lables', dbscan_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core Points for the First Cluster [0, 29, 5, 16, 19, 1, 2, 191, 23, 24, 87, 3, 26, 11, 21, 17, 10, 60, 49, 59, 38, 6, 31, 20, 30, 36, 40, 68, 27, 46, 50, 32, 51, 47, 54, 55, 52, 64, 44, 63, 35, 62, 112, 65, 48, 37, 34, 25, 33, 118, 70, 66, 69, 72, 41, 71, 78, 434, 134, 79, 74, 76, 142, 77, 86, 190, 80, 82, 132, 56, 94, 85, 90, 89, 83, 88, 280, 101, 123, 93, 114, 14, 113, 103, 96, 97, 102, 105, 121, 98, 107, 91, 73, 138, 124, 109, 108, 117, 104, 116, 61, 115, 122, 119, 133, 92, 140, 150, 99, 149, 136, 127, 110, 126, 141, 128, 168, 151, 166, 135, 95, 129, 277, 137, 148, 206, 53, 205, 158, 156, 157, 180, 170, 42, 169, 163, 165, 216, 171, 130, 131, 442, 139, 143, 175, 184, 167, 164, 178, 154, 22, 153, 285, 217, 161, 146, 160, 188, 197, 174, 196, 183, 176, 179, 229, 213, 181, 199, 144, 194, 249, 203, 204, 344, 219, 192, 218, 147, 242, 233, 201, 225, 208, 209, 185, 237, 469, 195, 189, 198, 173, 240, 210, 202, 200, 223, 284, 263, 283, 207, 282, 214, 281, 288, 224, 238, 244, 162, 243, 394, 230, 232, 239, 250, 246, 273, 234, 248, 694, 226, 251, 256, 227, 255, 241, 252, 267, 274, 343, 264, 257, 253, 261, 15, 7, 467, 262, 272, 315, 271, 275, 57, 378, 235, 279, 308, 381, 268, 287, 291, 290, 310, 276, 309, 292, 411, 293, 317, 260, 311, 297, 296, 359, 560, 337, 278, 298, 613, 265, 313, 301, 295, 325, 307, 314, 385, 312, 304, 316, 321, 289, 320, 339, 327, 338, 152, 457, 302, 323, 515, 322, 333, 504, 305, 211, 396, 341, 326, 318, 328, 324, 372, 331, 347, 222, 346, 340, 334, 352, 402, 329, 364, 360, 363, 361, 319, 354, 350, 353, 348, 366, 351, 365, 373, 376, 367, 380, 356, 379, 746, 420, 335, 419, 384, 368, 383, 382, 388, 236, 387, 345, 386, 392, 510, 358, 435, 269, 429, 369, 401, 403, 456, 733, 374, 404, 355, 472, 377, 410, 416, 389, 415, 424, 215, 423, 397, 412, 573, 400, 398, 393, 405, 413, 418, 407, 417, 468, 532, 422, 414, 421, 430, 534, 508, 441, 431, 390, 428, 446, 432, 443, 439, 437, 406, 436, 454, 447, 451, 433, 448, 466, 438, 449, 444, 450, 460, 299, 522, 81, 425, 479, 665, 452, 482, 461, 465, 506, 399, 505, 517, 473, 494, 521, 471, 470, 480, 427, 514, 474, 481, 490, 476, 489, 659, 675, 707, 610, 488, 463, 477, 495, 551, 483, 496, 512, 509, 511, 507, 520, 492, 478, 306, 497, 499, 493, 540, 462, 539, 538, 485, 527, 500, 525, 513, 523, 577, 531, 563, 503, 550, 501, 491, 542, 617, 526, 552, 556, 543, 553, 528, 529, 564, 569, 541, 530, 562, 544, 555, 547, 554, 561, 607, 565, 571, 599, 572, 566, 619, 535, 533, 600, 585, 524, 586, 578, 559, 518, 558, 711, 568, 548, 567, 663, 458, 611, 645, 608, 591, 624, 570, 536, 627, 615, 587, 581, 601, 642, 557, 582, 716, 731, 616, 635, 583, 634, 730, 592, 597, 598, 670, 516, 602, 628, 640, 637, 605, 575, 630, 652, 620, 651, 609, 625, 664, 666, 667, 648, 614, 603, 668, 594, 643, 696, 595, 747, 692, 638, 644, 650, 629, 631, 623, 653, 626, 676, 660, 748, 646, 633, 699, 683, 632, 636, 641, 391, 677, 671, 639, 649, 679, 687, 654, 681, 580, 680, 656, 686, 678, 682, 708, 717, 701, 710, 712, 693, 722, 685, 574, 697, 720, 704, 698, 703, 484, 725, 705, 719, 724, 714, 723, 729, 740, 743, 690, 742, 700, 688, 732, 745, 735, 737, 741, 576, 709, 750, 759, 738, 718, 721, 726, 766, 734, 765, 752, 764, 727, 751, 758, 739, 756, 669, 755, 657, 754, 760, 757, 713, 736, 728, 689, 749, 647, 744, 761, 545, 618, 612, 674, 658, 762]\n",
      "Border Points for the First Cluster [9, 43, 18, 28, 75, 84, 106, 111, 220, 187, 182, 67, 100, 155, 231, 254, 332, 221, 270, 303, 286, 300, 357, 258, 330, 371, 375, 294, 395, 537, 440, 453, 445, 459, 426, 475, 487, 498, 502, 549, 590, 604, 584, 259, 486, 622, 606, 172, 212, 662, 589, 695, 691, 684, 655, 120, 266, 702, 464, 763, 596, 753, 39, 159, 673, 715, 661, 12, 546, 593, 519, 706, 579, 588, 409, 362, 336, 455, 342, 672, 349, 228, 245, 408, 177, 193, 247, 145, 125, 186, 58]\n"
     ]
    }
   ],
   "source": [
    "print('Core Points for the First Cluster', final_core_points[0])\n",
    "print('Border Points for the First Cluster', final_border_points[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4905652b14e4b7eb92899b78ac499a22c488804455b27940a322fd82aaf71031"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
