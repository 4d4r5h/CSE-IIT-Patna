{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa123827",
   "metadata": {},
   "source": [
    "## Assignment 3\n",
    "### Foundations of Machine Learning (CS564)\n",
    "\n",
    "### *HMM model for PoS tagging on the Brown dataset*\n",
    "\n",
    "<table style=\\\"font-size:15px\\\">\n",
    "    <thead>\n",
    "        <td><b>Name of Student</b></td>\n",
    "        <td><b>Roll No.</b></td>\n",
    "        <td><b>Date</b></td>\n",
    "    </thead>\n",
    "    <tr>\n",
    "        <td>M. Maheeth Reddy</td>\n",
    "        <td>1801CS31</td>\n",
    "        <td>09-Nov-2021</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421121e3",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f30c7131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import stat\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import KFold, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8703f9c4",
   "metadata": {},
   "source": [
    "# function to get all the states for hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48204a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_states(state_seq):\n",
    "    states = dict(Counter(state_seq))\n",
    "    return states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251085a5",
   "metadata": {},
   "source": [
    "# function to create the initial probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d995bf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_initial_prob(states):\n",
    "    return {state: states[state]/sum(states.values()) for state in states.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d1e87f",
   "metadata": {},
   "source": [
    "# function to create the state transition probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b96377c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transition_prob(data_seq, states):\n",
    "    transit_prob = {}\n",
    "\n",
    "    for row in states.keys():\n",
    "        transit_prob[row] = {}\n",
    "        for col in states.keys():\n",
    "            transit_prob[row][col] = 0\n",
    "\n",
    "    for sample_seq in data_seq:\n",
    "        for i in range(len(sample_seq)-1):\n",
    "            transit_prob[sample_seq[i]][sample_seq[i+1]] += 1\n",
    "\n",
    "    for row in states.keys():\n",
    "        for col in states.keys():\n",
    "            transit_prob[row][col] = (transit_prob[row][col]+1)/(states[row]+len(states))\n",
    "\n",
    "    return transit_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c727a0",
   "metadata": {},
   "source": [
    "# function to create the emission probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "459f4900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emission_prob(data_obs, data_seq, states, corpus):\n",
    "    emiss_prob = {}\n",
    "\n",
    "    for state in states.keys():\n",
    "        emiss_prob[state] = {}\n",
    "        for obs in corpus.keys():\n",
    "            emiss_prob[state][obs] = 0\n",
    "\n",
    "    for t in range(len(data_seq)):\n",
    "        for w in range(len(data_seq[t])):\n",
    "            emiss_prob[data_seq[t][w]][data_obs[t][w]] += 1\n",
    "\n",
    "    for state in states.keys():\n",
    "        for obs in corpus.keys():\n",
    "            emiss_prob[state][obs] = (emiss_prob[state][obs]+1)/(states[state]+len(corpus))\n",
    "\n",
    "    return emiss_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea51700",
   "metadata": {},
   "source": [
    "# function to implement Viterbi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99d145fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_algorithm(initial_prob, transit_prob, emiss_prob, states, obs_seq):\n",
    "    i = 0\n",
    "    tree = [{}]\n",
    "    state_keys = list(states.keys())\n",
    "\n",
    "    for state in state_keys:\n",
    "        tree[0][state] = {'p':initial_prob[state]*emiss_prob[state][obs_seq[0]] if emiss_prob[state].get(obs_seq[0]) != None else 0, 'prev':-1}\n",
    "\n",
    "    for i in range(1, len(obs_seq)):\n",
    "        tree.append({})\n",
    "\n",
    "        for curr_state in state_keys:\n",
    "            max_prob = 0\n",
    "            prev = state_keys[0]\n",
    "\n",
    "            for prev_state in state_keys:\n",
    "                prob = tree[i-1][prev_state]['p']*transit_prob[prev_state][curr_state]*emiss_prob[curr_state][obs_seq[i]] if emiss_prob[curr_state].get(obs_seq[i]) != None else 0\n",
    "                \n",
    "                if prob >= max_prob:\n",
    "                    max_prob = prob\n",
    "                    prev = prev_state\n",
    "\n",
    "            tree[i][curr_state] = {'p': max_prob, 'prev': prev}\n",
    "\n",
    "    max_prob_state = state_keys[0]\n",
    "    for state in state_keys[1:]:\n",
    "        if tree[i][state]['p'] > tree[i][max_prob_state]['p']:\n",
    "            max_prob_state = state\n",
    "\n",
    "    pred_state_seq = [max_prob_state]\n",
    "    while(i > 0):\n",
    "        pred_state_seq.append(tree[i][max_prob_state]['prev'])\n",
    "        max_prob_state = tree[i][max_prob_state]['prev']\n",
    "        i -= 1\n",
    "\n",
    "    pred_state_seq.reverse()\n",
    "    return pred_state_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc80181a",
   "metadata": {},
   "source": [
    "# function calculate the forward probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1dc4b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forward_prob(initial_prob, transit_prob, emiss_prob, states, obs_seq):\n",
    "    state_keys = list(states.keys())\n",
    "    alpha = [{}]\n",
    "    for state in state_keys:\n",
    "        alpha[0][state] = initial_prob[state]*emiss_prob[state][obs_seq[0]] if emiss_prob[state].get(obs_seq[0]) != None else 0\n",
    "\n",
    "    for t in range(1, len(obs_seq)):\n",
    "        alpha.append({})\n",
    "        for curr_state in state_keys:\n",
    "            sum_prob = 0\n",
    "            for prev_state in state_keys:\n",
    "                sum_prob += (alpha[t-1][prev_state]*transit_prob[prev_state][curr_state])\n",
    "\n",
    "            alpha[t][curr_state] = emiss_prob[curr_state][obs_seq[t]]*sum_prob if emiss_prob[curr_state].get(obs_seq[t]) != None else 0\n",
    "\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c9616f",
   "metadata": {},
   "source": [
    "# function calculate the backward probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32bb35d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backward_prob(initial_prob, transit_prob, emiss_prob, states, obs_seq):\n",
    "    # T = len(obs_seq)\n",
    "    state_keys = list(states.keys())\n",
    "    beta = [{} for i in range(len(obs_seq))]\n",
    "\n",
    "    for state in state_keys:\n",
    "        beta[len(obs_seq)-1][state] = 1\n",
    "\n",
    "    for t in range(len(obs_seq)-2, -1, -1):\n",
    "        for curr_state in state_keys:\n",
    "            sum_prob = 0\n",
    "            for next_state in state_keys:\n",
    "                if emiss_prob[next_state].get(obs_seq[t+1]) != None:\n",
    "                    sum_prob += (beta[t+1][next_state]*transit_prob[curr_state][next_state]*emiss_prob[next_state][obs_seq[t+1]])\n",
    "\n",
    "            beta[t][curr_state] = sum_prob\n",
    "\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80b9785d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_temp_variables(initial_prob, transit_prob, emiss_prob, states, alpha, beta, obs_seq):\n",
    "    state_keys = list(states.keys())\n",
    "    y = [{} for i in range(len(obs_seq))]\n",
    "    epi = [{} for i in range(len(obs_seq))]\n",
    "\n",
    "    for t in range(0, len(obs_seq)):\n",
    "        for state in state_keys:\n",
    "            sum_y = 0\n",
    "            for all_s in state_keys:\n",
    "                sum_y += (alpha[t][all_s]*beta[t][all_s])\n",
    "\n",
    "            y[t][state] = (alpha[t][state]*beta[t][state])/sum_y if sum_y > 0 else 0\n",
    "\n",
    "    for t in range(0, len(obs_seq)-1):\n",
    "        for i in state_keys:\n",
    "            epi[t][i] = {}\n",
    "\n",
    "            for j in state_keys:\n",
    "                sum_epi = 0\n",
    "                for k in state_keys:\n",
    "                    for w in state_keys:\n",
    "                        if emiss_prob[w].get(obs_seq[t+1]) != None:\n",
    "                            sum_epi += (alpha[t][k]*transit_prob[k][w]*beta[t+1][w]*emiss_prob[w][obs_seq[t+1]])\n",
    "\n",
    "                if (emiss_prob[j].get(obs_seq[t+1]) != None) and sum_epi > 0:\n",
    "                    epi[t][i][j] = (alpha[t][i]*transit_prob[i][j]*beta[t+1][j]*emiss_prob[j][obs_seq[t+1]])/sum_epi \n",
    "                else:\n",
    "                    epi[t][i][j] = 0\n",
    "\n",
    "    return y, epi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c27fe1",
   "metadata": {},
   "source": [
    "# function to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e36ef013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(initial_prob, transit_prob, emiss_prob, states, x_train, y_train, epochs):\n",
    "    samples = x_train.shape[0]\n",
    "    state_keys = list(states.keys())\n",
    "\n",
    "    for epoch in range(0,epochs):\n",
    "        print('Epoch ', (epoch+1), end='\\r')\n",
    "        alpha,beta = [],[]\n",
    "        y,epi = [],[]\n",
    "        \n",
    "        for r in range(0, samples):\n",
    "            alpha.append(get_forward_prob(x_train[r]))\n",
    "            beta.append(get_backward_prob(x_train[r]))\n",
    "            temp1, temp2 = get_temp_variables(alpha[r], beta[r], x_train[r])\n",
    "            y.append(temp1)\n",
    "            epi.append(temp2)\n",
    "\n",
    "        for state in state_keys:\n",
    "            initial_prob[state] = 0\n",
    "            for r in range(0, samples):\n",
    "                initial_prob[state] += (y[r][0][state]/samples)\n",
    "\n",
    "        for i in state_keys:\n",
    "            for j in state_keys:\n",
    "                num,den = 0,0\n",
    "                for r in range(0, samples):\n",
    "                    for t in range(0, len(epi[r])-1):\n",
    "                        num += epi[r][t][i][j]\n",
    "                        den += y[r][t][i]\n",
    "\n",
    "                transit_prob[i][j] = num/den if den > 0 else 0\n",
    "\n",
    "        for i in state_keys:\n",
    "            for r in range(0, samples):\n",
    "                for k in x_train[r]:\n",
    "                    num,den = 0,0\n",
    "                    for t in range(0, len(y[r])):\n",
    "                        if x_train[t] == k:\n",
    "                            num += y[r][t][i]\n",
    "                        den += y[r][t][i]\n",
    "\n",
    "                emiss_prob[i][j] = num/den if den > 0 else 0\n",
    "\n",
    "    return initial_prob, transit_prob, emiss_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11af3b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obs_seq(sentences):\n",
    "    corpus = {}\n",
    "    state_seq = []\n",
    "\n",
    "    data_obs,data_seq = [],[]\n",
    "\n",
    "    for sent in sentences:\n",
    "        words = sent.split(' ')\n",
    "        sent_tag_list,sent_word_list = [],[]\n",
    "        for word in words:\n",
    "            word_split = word.rsplit('/', 1)\n",
    "            word, tag = word_split[0], word_split[1]\n",
    "            sent_tag_list.append(tag)\n",
    "            sent_word_list.append(word)\n",
    "\n",
    "            if corpus.get(word) == None:\n",
    "                corpus[word] = 1\n",
    "            else:\n",
    "                corpus[word] += 1\n",
    "            state_seq.append(tag)\n",
    "\n",
    "        data_obs.append(sent_word_list)\n",
    "        data_seq.append(sent_tag_list)\n",
    "\n",
    "    return data_obs, data_seq, corpus, state_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40b7dc8",
   "metadata": {},
   "source": [
    "# function to get the sentences from Brown Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a3382ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_sentences(filename):\n",
    "    sentences = []\n",
    "    with open(filename, 'r') as infile:\n",
    "        for line in infile:\n",
    "            sentences.append(line.rstrip())\n",
    "    print('Number of sentences in the brown dataset are', len(sentences))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b17011",
   "metadata": {},
   "source": [
    "# function for all predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca56b077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_write_preds(data_obs, outfile, init, trans, emi, states):\n",
    "    outputfile = open(outfile, 'w')\n",
    "    all_predictions = []\n",
    "    for words in data_obs:\n",
    "        pred_seq = viterbi_algorithm(init, trans, emi, states, words)\n",
    "        all_predictions.append(pred_seq)\n",
    "        for i in range(len(pred_seq)):\n",
    "            outputfile.write(words[i] + '\\t' + pred_seq[i] + '\\n')\n",
    "        outputfile.write('\\n')\n",
    "\n",
    "    outputfile.close()\n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d71174a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_state_seq(data_seq):\n",
    "    vec = []\n",
    "    for seq in data_seq:\n",
    "        vec.extend(seq)\n",
    "\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733a74d6",
   "metadata": {},
   "source": [
    "# driver function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b15859fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def driver(filename, outfile):\n",
    "    sentences = get_all_sentences(filename)\n",
    "    train_sentences, test_sentences = train_test_split(sentences, test_size=0.2, random_state=117)\n",
    "    data_obs, data_seq, corpus, state_seq = get_obs_seq(train_sentences)\n",
    "    test_data_obs, test_data_seq, test_corpus, test_state_seq = get_obs_seq(test_sentences)\n",
    "    len_corpus = len(corpus)\n",
    "    states = dict(Counter(state_seq))\n",
    "    state_keys = list(states.keys())\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "    np_obs = np.array(data_obs)\n",
    "    np_seq = np.array(data_seq)\n",
    "\n",
    "    for train_index, test_index in kf.split(np_obs):\n",
    "        x_train, y_train = np_obs[train_index], np_seq[train_index]\n",
    "        x_test, y_test = np_obs[test_index], np_seq[test_index]\n",
    "\n",
    "        init = create_initial_prob(states)\n",
    "        trans = create_transition_prob(y_train, states)\n",
    "        emi = create_emission_prob(x_train, y_train, states, corpus)\n",
    "\n",
    "        pred_seq = []\n",
    "        for t in range(0, len(x_test)):\n",
    "            pred_seq.extend(viterbi_algorithm(init, trans, emi, states, x_test[t]))\n",
    "\n",
    "        print(precision_recall_fscore_support(flatten_state_seq(y_test), pred_seq, labels=state_keys),end='\\n\\n')\n",
    "\n",
    "    init = create_initial_prob(states)\n",
    "    trans = create_transition_prob(y_train, states)\n",
    "    emi = create_emission_prob(x_train, y_train, states, corpus)\n",
    "\n",
    "    test_pred_seq = get_and_write_preds(test_data_obs, outfile, init, trans, emi, states)\n",
    "    with open('precision_recall_fscore.txt', 'w') as infile:\n",
    "        print('precision, recall and fscore respectively\\n',file=infile)\n",
    "        print(precision_recall_fscore_support(flatten_state_seq(test_data_seq),flatten_state_seq(test_pred_seq), labels=state_keys), file=infile)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67692746",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7ef33a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in the brown dataset are 27491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-1ace2a456e46>:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_obs = np.array(data_obs)\n",
      "<ipython-input-15-1ace2a456e46>:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_seq = np.array(data_seq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.86756542, 0.93788922, 0.98386531, 0.95824176, 0.89314463,\n",
      "       0.84454303, 0.97751346, 0.91765221, 0.86735898, 0.91824752,\n",
      "       0.99097938, 0.152     ]), array([0.98637548, 0.89421875, 0.98490169, 0.88779666, 0.96612764,\n",
      "       0.8203758 , 0.99698929, 0.96100917, 0.83465819, 0.82911909,\n",
      "       0.70875576, 0.44705882]), array([0.92316347, 0.91553351, 0.98438323, 0.92167511, 0.92820371,\n",
      "       0.83228402, 0.98715532, 0.93883038, 0.85069444, 0.8714102 ,\n",
      "       0.8264374 , 0.22686567]), array([ 9982, 19200,  2848, 14242, 10451,  5801, 11293,  4360,  4403,\n",
      "        2452,  1085,    85]))\n",
      "\n",
      "(array([0.87623805, 0.93923751, 0.98381422, 0.95954147, 0.89173296,\n",
      "       0.84214223, 0.97681357, 0.91853809, 0.86710189, 0.91331546,\n",
      "       0.98985507, 0.04481132]), array([0.98034303, 0.89432185, 0.98485382, 0.88611361, 0.96717314,\n",
      "       0.82151422, 0.99634814, 0.96462428, 0.83460503, 0.82253521,\n",
      "       0.6878147 , 0.17431193]), array([0.92537178, 0.91622954, 0.98433374, 0.92136691, 0.92792225,\n",
      "       0.83170034, 0.98648416, 0.94101725, 0.85054317, 0.86555156,\n",
      "       0.81164587, 0.07129456]), array([10378, 19531,  2839, 14453, 10662,  5838, 11501,  4325,  4456,\n",
      "        2485,   993,   109]))\n",
      "\n",
      "(array([0.87453362, 0.93605617, 0.97712305, 0.95680787, 0.89089029,\n",
      "       0.84397906, 0.97645654, 0.91385768, 0.85791578, 0.91457961,\n",
      "       0.99048913, 0.02197802]), array([0.97920917, 0.88965869, 0.98257232, 0.88091093, 0.96265599,\n",
      "       0.82385009, 0.9944401 , 0.96599907, 0.83589273, 0.82526231,\n",
      "       0.67437558, 0.13513514]), array([0.92391603, 0.91226787, 0.97984011, 0.91729214, 0.92538382,\n",
      "       0.8337931 , 0.98536627, 0.93920525, 0.84676109, 0.86762834,\n",
      "       0.80242157, 0.03780718]), array([10293, 19630,  2869, 14359, 10738,  5870, 11511,  4294,  4363,\n",
      "        2478,  1081,    74]))\n",
      "\n",
      "(array([0.87421553, 0.94291426, 0.97591215, 0.9619826 , 0.8952805 ,\n",
      "       0.85194435, 0.9772291 , 0.92176508, 0.86292187, 0.91870968,\n",
      "       0.997151  , 0.08786611]), array([0.98019702, 0.89490882, 0.9874552 , 0.89394467, 0.9679407 ,\n",
      "       0.83511103, 0.99617574, 0.96777081, 0.85384263, 0.84160757,\n",
      "       0.68027211, 0.25609756]), array([0.9241778 , 0.91828457, 0.98164974, 0.92671651, 0.93019383,\n",
      "       0.84344371, 0.98661147, 0.94420788, 0.85835824, 0.87847008,\n",
      "       0.80878105, 0.13084112]), array([ 9948, 18974,  2790, 14351, 10387,  5719, 11244,  4468,  4372,\n",
      "        2538,  1029,    82]))\n",
      "\n",
      "(array([0.86754608, 0.93748273, 0.9819469 , 0.96073536, 0.88831122,\n",
      "       0.84824047, 0.97739825, 0.91510474, 0.86341022, 0.9080361 ,\n",
      "       0.99456522, 0.07094595]), array([0.98079673, 0.89108391, 0.98508523, 0.89003364, 0.96720671,\n",
      "       0.81192982, 0.99670739, 0.9646676 , 0.85109229, 0.8365004 ,\n",
      "       0.6847521 , 0.17213115]), array([0.92070189, 0.91369464, 0.98351356, 0.92403405, 0.92608167,\n",
      "       0.82968806, 0.98695839, 0.93923277, 0.857207  , 0.87080157,\n",
      "       0.81108033, 0.10047847]), array([ 9790, 19033,  2816, 14268, 10246,  5700, 11541,  4302,  4486,\n",
      "        2526,  1069,   122]))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "driver(\"Brown_train.txt\", \"test_pred.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934aac16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
